#User Testing

User testing is a technique that is used to establish whether a tool is meeting the needs of the user. This is not the same as meeting their wants, which are often quite different. It is primarily focused on making sure that the tool is well formed. This means categorising the features into those that are supporting the user, those that might be frustrating the user, and those that are extraneous and can be removed. 

User testing has features in common with scientific psychological studies of usability, but should not be confused with them. With a few exceptions, large numbers of participants are not feasible and therefore quantitative studies with a reasonable degree of statistical power are hard to achieve. For this reason practical user testing tends to be more qualitative. This means that we are interested in rich narrative information concerning how users interact with the tools that we make. 

##Usability

Testing is aimed at establishing the level of usability of the tool at hand. Usability is split into three components.

Effectiveness - Does it do what it needs to do?
Efficiency - how hard is it to do?
Satisfaction - How did it make you feel?

If the tool is effective, efficient and provides the user with satisfaction when they use it, it is said to be usable. 

##Participants

Research has demonstrated that the optimal number of participants for a particular persona or user cluster is between 5 and 8. These participants should be representative of that set of users as a whole.

Sometimes particular demographics are required for testing. In this case the researcher should write a screener document. This describes the requirements for the users, so the individual responsible for recruiting the participants can easily check if the participants are appropriate. 

For example
>Participants can be either male or female, should be between the ages of 25 and 45, and be experienced players of bingo.

##In person vs remote testing
In person testing is the ideal form of user testing. This makes it much easier to guide the participant through the test, and the researcher can observe the participants' facial expressions and reactions much more easily. It is possible to conduct user research over video conference. Under these circumstances it is often the case that you cannot see the face of the user. It may be necessary to ask supplementary questions about the users level of frustration or satisfaction as they participate

##Task Types

###Specific Tasks

Specific tasks help determine how well the system is performing for a set of functions. It is important that the task chosen is representative of a real-world use-case, and is minimally artificial. This means that plausible data should be used. The benefit of specific tasks is that the results for individuals are directly comparable. The researcher can derive statistics for task completion, or time to completion (e.g. 67% of participants could complete the task. Median time was 43 seconds).

If testing with only wireframes, you should create a specific task. This is because the number of forks in the road is necessarily limited when using paper. You can also use specific tasks with working systems. 

###Open Ended Tasks

When using an actual system, you can let users explore. Get them to explain what they're doing as they go along, and why they click on specific areas of the tool. This can give insights into how users make use of tools.

##Materials for User Testing
If you have a working system, then you will be using the system for testing. If you are at the wireframe stage, you will need to use these. Arrange your wireframes into a narrative - a plausible workflow for a user. Make sure that the data in the wireframes is reasonable. This may involve some prior consultation with the client before the testing session begins. Make sure that each wireframe in turn can be reached from the previous one. Make sure that the wireframe has good micro-copy for elements such as buttons and menus. These are really important and if they are obviously too vague ("OK" and "Cancel") then these should be changed before the testing. There is no need to test what has already been found out. 

##Opening script for candidates
> Thank you for agreeing to participate in our testing session today. All your responses will be anonymised, and you will not be identifiable in any of the reports from the testing sessions. The information that you will provide us with will be used only to improve the system.

> This is not a test of your abilities. The purpose of this session is to establish where the system is supporting you, and where it might be frustrating you.

> At some stages you may feel confused, and lost. Don't worry - you can take your time, and ask questions if you don't know.

> We'd like you to think aloud as you go. Just let us know what you're thinking as you are carrying out the tasks.
> Please let me know if you have any questions about the session.

##Questions to ask during testing
Testing sessions should be semi-structured. This means that you should be prepared to ask a set of questions to common to each participant, but you should also be prepared to deviate temporarily from the structure should a topic of interest arise. A good testing session will typically start with easy questions, for example demographic questions, and move into progressively more complex areas. This allows the participant to become confident as the testing session proceeds.

###Demographic Questions

* Age
* How long at company
* Position
* Unit/Function/Department
* How often do you do [x] (Establishing familiarity)
* How much do you use system [x] (Establish technical proficiency)


###Key Questions for a particular page/component

* What can you see on this page?
* Is this what you expected to see?
* What would you want to do next?
* What do you think will happen if you click on that?
* How would you perform [ function x ]?

If you're not sure about whether a feature is important or not, leave it out. If it's important the participants will notice. If it's not they will be able to carry on.

If a participant is hesitating, don't be afraid to let them think. After a while you can ask them what they are thinking, and what is making them hesitate. This can be revealing. After that you can prompt them with the answer. 
